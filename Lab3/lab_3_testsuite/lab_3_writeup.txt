Lab 3 Write up
by David Krug and Nathaniel Imel

===================================================================================================

1. Initial and final [incr tsdb()] runs results for test corpus and test suite
	1.1.initial, testsuite
		43 out of 54 parsed
		21 out of 22 positive items
		22 out of 32 negative items parsed (i.e. huge overgeneration)
	We believe this is caused by the fact we didn't really handle agreement yet. All we did
	was specify in the choices file the kinds of agreement categories  and added things like
	_1dl.incl_v_rel to the predications on the new lexical items (i.e. verb clitics as aux types).
	I verified this by checking in the feature structures for our parses, which didn't show the
	necessary PERNUM values. 

	1.1.2 average number of parses per parsed item: 1.57
	1.1.3 Most ambiguous example received: 2
	1.1.4 Ambiguity:
		A major source is the fact that the clitics are being parsed as pronouns, and the pronouns
	are being parsed as clitics. We also think that things which should be _pron_rels are _n_rels.
		
	1.2 initial, corpus (using i-length < 8
		1.2.1 How many items parsed? 24 out of 563 (4.3%)
		1.2.2 What is the average number of parses per parsed item? 1.50
		1.2.3 How many parses did the most ambiguous item receive?
		      There were two sentences that received 3 trees:
		      
		      'Ala iri i.' and 'Ara vavuen.'
		      
		1.2.4 What sources of ambiguity can you identify?

		      Since the IGT for this sentence is:

		      Ala iri i
		      3pl bury 3sg
		      'They buried him.'

		      Aru vavuen.
		      3dl refuse
		      'They refused.'

		      For the first sentence, there is the pronoun/clitic confusion.
		      There is also a lexical entry for ala_1 and ala_2. Ala_2 is
		      a noun I added last lab that I need to delete (I didn't see
		      ala_1 which fills the role of _pron_rel that I need).

		      For the second, there are two parses where 'aru' is a verb
		      clitic, which it shouldn't be. The nominal parse is a result
		      of the previous lab, but it is implemented incorrectly --
		      I need to specify that it is a _pron_rel, instead of
		      a _3dl_n_rel. Also, since 'vavuen' has a subtree that is
		      VP -> V -> vavuen , with BASIC-HEAD-OPT-COMP appling
		      and another that is
		      V -> vavuen , with that rule not in the tree
		      Maybe the verb's complement requirement is getting
		      discharged at different places?'
	
	1.3 final, corpus
		1.3.1 How many items parsed?
		1.3.2 What is the average number of parses per parsed item?
		1.3.3 How many parses did the most ambiguous item receive?
		1.3.4 What sources of ambiguity can you identify?
	
	1.4 final, testsuite
		1.4.1 How many items parsed?
		1.4.2 What is the average number of parses per parsed item?
		1.4.3 How many parses did the most ambiguous item receive?
		1.4.4 What sources of ambiguity can you identify?


===================================================================================================

2. For 10 items (if you have at least that many parsing), do any of the parses look reasonable in
the semantics?

    1. Initial test suite run:

       1. 

       2.

       3.

       4.

       5.

       6.

       7.

       8.

       9.

       10.

    2. Final run diff:

===================================================================================================

3. Documentation of the phenomena you have added to your testsuite
We added:
- the rest of the NP (determiners)
- coordination
- tense

	3.1 Determiners.
		Titan has two main types of demonstratives, the first (tita, titan,	tito, ilatu) can be
	either the prenominal determiner to an NP or the independent head of an NP. The second (ita,
	itan, ito, latu) can only be the postnominal modifer of an NP.
	
	Here are some examples:
	
	# Prenominal determiner
	Source: author
	Vetted: f
	Judgment: g
	Phenomena: {determiners}
	Tita manuai kip.
	this eagle lie
	This eagle lies.
	
	# Independent head
	Source: author
	Vetted: f
	Judgment: g
	Phenomena: {determiners}
	Tita kip.
	this lie
	This lies.
	
	# Postnominal modifier
	Source: author
	Vetted: f
	Judgment: g
	Phenomena: {determiners}
	Manuai ita kip.
	eagle this lie
	This eagle lies.
	
	# Wrong determiner in prenominal position	
	Source: author
	Vetted: f
	Judgment: u
	Phenomena: {determiners}
	Ita manuai kip.
	this eagle lie
	This eagle lies.
	
	
	3.2 Coordination
		Titan has polysyndetic coordination with two possible conjunctions, 'pe' (and) and 'ne'
	(or) that occur between each coordinated element. 'Pe' can conjoin two VPs or two NPs, but
	'ne' can only conjoin two NPs. If two singular NPs are coordinated, the resulting NP is dual.
	The entire paradigm from coordinand person and number to coordination person and number is
	not given in the descriptive resource. 
	
	Here are some examples.
	
	# Coordination of VPs
	Source: author
	Vetted: f
	Judgment: g
	Phenomena: {coordination}
	Yo o kip pe oi a kip.
	1sg 1sg.nfut lie and 2sg 2sg.nfut lie.
	'I lie and you lie.'
	
	# Coordination of subject NPs
	Source: author
	Vetted: f
	Judgment: g
	Phenomena: {coordination}
	Yo pe oi yoru kip.
	1sg and 2sg 1dl.incl lie.
	'I and you lie.'
	
	# Failed VP coordination using 'ne'
	Source: author
	Vetted: f
	Judgment: u
	Phenomena: {coordination}
	Yo o kip ne oi a kip.
	1sg 1sg.nfut lie or 2sg 2sg.nfut lie.
	'I lie or you lie.'
	'I lie and you lie.'
	
	# Wrong verbal clitic agreement
	Source: author
	Vetted: f
	Judgment: u
	Phenomena: {coordination}
	Yo pe oi yoya kip.
	1sg and 2sg 1pl lie.
	'I and you lie.'
	
	3.3 Tense
	Titan has two tenses: future and non-future. Future tense is marked by use of the irrealis verbal clitic, and non-future is marked with the realis clitic. The subject and irrealis clitic must agree in person.
	
	Here are some examples:
	
	# Future tense clitic agreement
	Source: author
	Vetted: f
	Judgment: g
	Phenomena: {tense, agreement}
	Yo ku kip
	1sg 1sg.fut lie
	'I will lie.'
	
	#Future tense clitic with wrong agreement
	Source: author
	Vetted: f
	Judgment: u
	Phenomena: {tense, agreement}
	Yo ka kip
	1sg n.sg.fut lie
	'I will lie.'
	

===================================================================================================

4. Documentation of the improvements you made the morphotactic choices. What did you change and why?
Please include IGT that illustrate the effects of the changes so I can test them out

		The first change we made to the morphotactic choices was to merge verb_pc7 and verbpc_9,
	verb_pc8 and verb_pc11, and  verb_pc10 and verb_pc12. In all pairs, the only difference between
	the two were the inputs.

	Here are some parses that were effected by this change.

	Yo  u        kip.
	1sg 1sg.nfut lie
	I lie.

	Manuai i        kip
	eagle  3sg.nfut lie
	Eagle lies.

	Ala  la ta    ni
	they go catch fish
	They go fishing.

		Prior to our morphotactic change, the verb 'u' underwent verb_pc12 lexical rule. After the
	change,	the verb underwent verb_pc10 lexical rule, and the semantics did not change. Similar
	changes occurred for the other examples as well.
	
		The second change we made to the morphotactic choices was to add 

